{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "39793116",
      "metadata": {
        "id": "39793116"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41354c94",
      "metadata": {
        "id": "41354c94"
      },
      "source": [
        "Требуется реализовать функцию батч-нормализации без использования стандартной функции со следующими упрощениями:\n",
        "\n",
        "* Параметр Бета принимается равным 0.\n",
        "* Параметр Гамма принимается равным 1.\n",
        "* Функция должна корректно работать только на этапе обучения.\n",
        "* Вход имеет размерность число элементов в батче * длина каждого инстанса."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b454d1d6",
      "metadata": {
        "id": "b454d1d6",
        "outputId": "9723ffc7-d171-4565-c311-05c6fa568f92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "def custom_batch_norm1d(input_tensor, eps):\n",
        "#     среднее значение\n",
        "    mean = torch.mean(input_tensor, dim=0)\n",
        "#     дисперсия\n",
        "    var = torch.var(input_tensor, dim=0, unbiased=False)\n",
        "    normed_tensor = (input_tensor - mean)/(torch.sqrt(var + eps))\n",
        "    return normed_tensor\n",
        "\n",
        "\n",
        "input_tensor = torch.Tensor([[0.0, 0, 1, 0, 2], [0, 1, 1, 0, 10]])\n",
        "batch_norm = nn.BatchNorm1d(input_tensor.shape[1], affine=False)\n",
        "\n",
        "\n",
        "all_correct = True\n",
        "for eps_power in range(10):\n",
        "    eps = np.power(10., -eps_power)\n",
        "    batch_norm.eps = eps\n",
        "    batch_norm_out = batch_norm(input_tensor)\n",
        "    custom_batch_norm_out = custom_batch_norm1d(input_tensor, eps)\n",
        "\n",
        "    all_correct &= torch.allclose(batch_norm_out, custom_batch_norm_out)\n",
        "    all_correct &= batch_norm_out.shape == custom_batch_norm_out.shape\n",
        "print(all_correct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2b568e4",
      "metadata": {
        "id": "e2b568e4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "54b5683c",
      "metadata": {
        "id": "54b5683c"
      },
      "source": [
        "Требуется реализовать функцию батч-нормализации без использования стандартной функции со следующими упрощениями:\n",
        "\n",
        "* Функция должна корректно работать только на этапе обучения.\n",
        "* Вход имеет размерность число элементов в батче * длина каждого инстанса."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f743ef73",
      "metadata": {
        "id": "f743ef73",
        "outputId": "5e3e23e3-afe3-4ac8-dd90-d6259ec9e788"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# gamma = weight\n",
        "# betta = bias\n",
        "\n",
        "input_size = 7\n",
        "batch_size = 5\n",
        "input_tensor = torch.randn(batch_size, input_size, dtype=torch.float)\n",
        "\n",
        "eps = 1e-3\n",
        "\n",
        "def custom_batch_norm1d(input_tensor, weight, bias, eps):\n",
        "    mean = torch.mean(input_tensor, dim=0)\n",
        "    var = torch.var(input_tensor, dim=0, unbiased=False)\n",
        "    normed_tensor = ((input_tensor - mean)/(torch.sqrt(var + eps))*weight)+bias\n",
        "    return normed_tensor\n",
        "\n",
        "\n",
        "batch_norm = nn.BatchNorm1d(input_size, eps=eps)\n",
        "batch_norm.bias.data = torch.randn(input_size, dtype=torch.float)\n",
        "batch_norm.weight.data = torch.randn(input_size, dtype=torch.float)\n",
        "batch_norm_out = batch_norm(input_tensor)\n",
        "custom_batch_norm_out = custom_batch_norm1d(input_tensor, batch_norm.weight.data, batch_norm.bias.data, eps)\n",
        "print(torch.allclose(batch_norm_out, custom_batch_norm_out) \\\n",
        "      and batch_norm_out.shape == custom_batch_norm_out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00e92183",
      "metadata": {
        "id": "00e92183"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7c2a5575",
      "metadata": {
        "id": "7c2a5575"
      },
      "source": [
        "Реализуем работу слоя батч-нормализации на этапе предсказания.\n",
        "\n",
        "На этом этапе вместо статистик по батчу будем использовать экспоненциально сглаженные статистики из истории обучения слоя.\n",
        "\n",
        "В данном шаге вам требуется реализовать полноценный класс батч-нормализации без использования стандартной функции, \n",
        "принимающий на вход двумерный тензор. Осторожно, расчёт дисперсии ведётся по смещенной выборке, а расчет скользящего среднего \n",
        "по несмещенной."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c07a0c6",
      "metadata": {
        "id": "2c07a0c6",
        "outputId": "756f12d5-b2a8-461c-989c-fd3b34c39102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "input_size = 3\n",
        "batch_size = 5\n",
        "eps = 1e-1\n",
        "\n",
        "\n",
        "class CustomBatchNorm1d:\n",
        "    def __init__(self, weight, bias, eps, momentum):\n",
        "        self.weight = weight\n",
        "        self.bias = bias\n",
        "        self.eps = eps\n",
        "        self.momentum = momentum\n",
        "        self.mean = 0\n",
        "        self.var = 1\n",
        "        self.train = True\n",
        "\n",
        "        \n",
        "    def __call__(self, input_tensor):\n",
        "        if self.train == True:\n",
        "            mean = torch.mean(input_tensor, dim=0)\n",
        "            var = torch.var(input_tensor, dim=0, unbiased=False)\n",
        "            \n",
        "            self.mean = (1-self.momentum) * mean + self.momentum * self.mean\n",
        "            self.var = (1-self.momentum) * var * (batch_size/(batch_size-1)) + self.momentum * self.var\n",
        "            \n",
        "            normed_tensor = ((input_tensor - mean)/(torch.sqrt(var + self.eps)) * self.weight) + self.bias\n",
        "        \n",
        "        else:\n",
        "            normed_tensor = ((input_tensor - self.mean)/(torch.sqrt(self.var + self.eps)) * self.weight) + self.bias\n",
        "        \n",
        "        return normed_tensor\n",
        "\n",
        "    \n",
        "    def eval(self):\n",
        "        # В этом методе реализуем переключение в режим предикта.\n",
        "        self.train = False\n",
        "\n",
        "\n",
        "batch_norm = nn.BatchNorm1d(input_size, eps=eps)\n",
        "batch_norm.bias.data = torch.randn(input_size, dtype=torch.float)\n",
        "batch_norm.weight.data = torch.randn(input_size, dtype=torch.float)\n",
        "batch_norm.momentum = 0.5\n",
        "\n",
        "custom_batch_norm1d = CustomBatchNorm1d(batch_norm.weight.data,\n",
        "                                        batch_norm.bias.data, eps, batch_norm.momentum)\n",
        "\n",
        "all_correct = True\n",
        "\n",
        "for i in range(8):\n",
        "    torch_input = torch.randn(batch_size, input_size, dtype=torch.float)\n",
        "    norm_output = batch_norm(torch_input)\n",
        "    custom_output = custom_batch_norm1d(torch_input)\n",
        "    all_correct &= torch.allclose(norm_output, custom_output, atol=1e-04) \\\n",
        "        and norm_output.shape == custom_output.shape\n",
        "\n",
        "batch_norm.eval()\n",
        "custom_batch_norm1d.eval()\n",
        "\n",
        "for i in range(8):\n",
        "    torch_input = torch.randn(batch_size, input_size, dtype=torch.float)\n",
        "    norm_output = batch_norm(torch_input)\n",
        "    custom_output = custom_batch_norm1d(torch_input)\n",
        "    all_correct &= torch.allclose(norm_output, custom_output, atol=1e-04) \\\n",
        "        and norm_output.shape == custom_output.shape\n",
        "print(all_correct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b634f7c",
      "metadata": {
        "id": "5b634f7c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0451ea8f",
      "metadata": {
        "id": "0451ea8f"
      },
      "source": [
        "### BatchNorm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5197262f",
      "metadata": {
        "id": "5197262f"
      },
      "source": [
        "Реализуем батч-норм слой для четырехмерного входа (например, батч из многоканальных двумерных картинок) без использования \n",
        "стандартной реализации со следующими упрощениями:\n",
        "* Параметр Бета = 0.\n",
        "* Параметр Гамма = 1.\n",
        "\n",
        "Функция должна корректно работать только на этапе обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8151c84",
      "metadata": {
        "scrolled": false,
        "id": "c8151c84",
        "outputId": "6c0993e6-a02c-407e-d1ff-f6d6f2cc70ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "eps = 1e-3\n",
        "\n",
        "input_channels = 3\n",
        "batch_size = 3\n",
        "height = 10\n",
        "width = 10\n",
        "\n",
        "batch_norm_2d = nn.BatchNorm2d(input_channels, affine=False, eps=eps)\n",
        "\n",
        "input_tensor = torch.randn(batch_size, input_channels, height, width, dtype=torch.float)\n",
        "\n",
        "def custom_batch_norm2d(input_tensor, eps):\n",
        "    mean = torch.cat([torch.mean(input_tensor[:,i,:,:]).unsqueeze(0) \n",
        "                      for i in range(input_channels)], dim=0)\n",
        "    \n",
        "    var = torch.cat([torch.var(input_tensor[:,i,:,:], unbiased=False).unsqueeze(0) \n",
        "                     for i in range(input_channels)], dim=0)\n",
        "    \n",
        "    normed_tensor = torch.cat([((input_tensor[:,i,:,:] - mean[i])/torch.sqrt(var[i] + eps)).unsqueeze(1) \n",
        "                               for i in range(input_channels)], dim=1)\n",
        "    return normed_tensor\n",
        "\n",
        "\n",
        "norm_output = batch_norm_2d(input_tensor)\n",
        "custom_output = custom_batch_norm2d(input_tensor, eps)\n",
        "print(torch.allclose(norm_output, custom_output) and norm_output.shape == custom_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5187bab",
      "metadata": {
        "id": "c5187bab"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "18856c22",
      "metadata": {
        "id": "18856c22"
      },
      "source": [
        "### LayerNorm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a45163c",
      "metadata": {
        "id": "9a45163c"
      },
      "source": [
        "Реализуем нормализацию \"по каналу\" без использования стандартного слоя со следующими упрощениями:\n",
        "\n",
        "* Параметр Бета = 0.\n",
        "* Параметр Гамма = 1.\n",
        "* Требуется реализация только этапа обучения.\n",
        "\n",
        "Нормализация делается по всем размерностям входа, кроме нулевой.\n",
        "Обратите внимание, что размерность входа на данном шаге не фиксирована.\n",
        "Уточним, что в слое нормализации \"по каналу\" статистики считаются по всем размерностям, кроме нулевой."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5bd2134",
      "metadata": {
        "id": "c5bd2134",
        "outputId": "efdb69fc-a655-4b0c-e222-a4c8c71aff49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "eps = 1e-10\n",
        "\n",
        "\n",
        "def custom_layer_norm(input_tensor, eps):\n",
        "    mean = torch.cat([torch.mean(input_tensor[i]).unsqueeze(0) \n",
        "                      for i in range(0, input_tensor.size()[0])], dim=0)\n",
        "    \n",
        "    var = torch.cat([torch.var(input_tensor[i], unbiased=False).unsqueeze(0) \n",
        "                     for i in range(0, input_tensor.size()[0])], dim=0)\n",
        "    \n",
        "    normed_tensor = torch.cat([((input_tensor[i] - mean[i])/torch.sqrt(var[i] + eps)).unsqueeze(0) \n",
        "                               for i in range(0, input_tensor.size()[0])], dim=0)\n",
        "    return normed_tensor\n",
        "\n",
        "\n",
        "all_correct = True\n",
        "for dim_count in range(3, 9):\n",
        "    input_tensor = torch.randn(*list(range(3, dim_count + 2)), dtype=torch.float)\n",
        "    layer_norm = nn.LayerNorm(input_tensor.size()[1:], elementwise_affine=False, eps=eps)\n",
        "\n",
        "    norm_output = layer_norm(input_tensor)\n",
        "    custom_output = custom_layer_norm(input_tensor, eps)\n",
        "\n",
        "    all_correct &= torch.allclose(norm_output, custom_output, 1e-2)\n",
        "    all_correct &= norm_output.shape == custom_output.shape\n",
        "print(all_correct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e89d2b8",
      "metadata": {
        "id": "9e89d2b8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найти функцию активации, которая приводит к наименьшему затуханию градиента. "
      ],
      "metadata": {
        "id": "_8EdQ2EO7xXa"
      },
      "id": "_8EdQ2EO7xXa"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "898db9a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "898db9a3",
        "outputId": "9572e75c-83f4-48cb-852e-fd8049f13f94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n",
            "0.7372176972031593\n"
          ]
        }
      ],
      "source": [
        "seed = int(input())\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "NUMBER_OF_EXPERIMENTS = 200\n",
        "\n",
        "class SimpleNet(torch.nn.Module):\n",
        "    def __init__(self, activation):\n",
        "        super().__init__()\n",
        "\n",
        "        self.activation = activation\n",
        "        self.fc1 = torch.nn.Linear(1, 1, bias=False)  # one neuron without bias\n",
        "        self.fc1.weight.data.fill_(1.)  # init weight with 1\n",
        "        self.fc2 = torch.nn.Linear(1, 1, bias=False)\n",
        "        self.fc2.weight.data.fill_(1.)\n",
        "        self.fc3 = torch.nn.Linear(1, 1, bias=False)\n",
        "        self.fc3.weight.data.fill_(1.)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.activation(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "    def get_fc1_grad_abs_value(self):\n",
        "        np.random.seed(seed)\n",
        "        torch.manual_seed(seed)\n",
        "        return torch.abs(self.fc1.weight.grad)\n",
        "\n",
        "def get_fc1_grad_abs_value(net, x):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    \n",
        "    output = net.forward(x)\n",
        "    output.backward()  \n",
        "\n",
        "  # no loss function. Pretending that we want to minimize output\n",
        "  # In our case output is scalar, so we can calculate backward\n",
        "    \n",
        "    fc1_grad = net.get_fc1_grad_abs_value().item()\n",
        "    net.zero_grad()\n",
        "    return fc1_grad\n",
        "\n",
        "  # Trying different activations to get biggest gradient\n",
        "functions = ['ELU', 'Hardtanh', 'LeakyReLU', 'LogSigmoid',\n",
        "               'PReLU', 'ReLU', 'ReLU6', 'RReLU', 'SELU', 'CELU',\n",
        "               'Sigmoid', 'Softplus', 'Softshrink','Softsign',\n",
        "               'Tanh', 'Tanhshrink', 'Hardshrink']\n",
        "\n",
        "for current_name in functions:\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "\n",
        "  net = SimpleNet(activation=eval(\"torch.nn.{}()\".format(current_name)))\n",
        "\n",
        "fc1_grads = []\n",
        "for x in torch.randn((NUMBER_OF_EXPERIMENTS, 1)):\n",
        "  fc1_grads.append(get_fc1_grad_abs_value(net, x))\n",
        "\n",
        "print(np.mean(fc1_grads))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37d8188e",
      "metadata": {
        "id": "37d8188e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рассчитать градиенты весов сети для случая a=tanh и для случая a=ReLU"
      ],
      "metadata": {
        "id": "bvDpZHZ2HlBd"
      },
      "id": "bvDpZHZ2HlBd"
    },
    {
      "cell_type": "code",
      "source": [
        "def ReLU(x):\n",
        "    return max(0, x)\n",
        "\n",
        "def dReLU(x):\n",
        "    if x > 0:\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "# Tanh activation\n",
        "t1 =round((1 - math.tanh(math.tanh(math.tanh(math.tanh(100)))) ** 2) * (1 - math.tanh(math.tanh(math.tanh(100))) ** 2) \n",
        "          * (1 - math.tanh(math.tanh(100)) ** 2) * (1 - math.tanh(100) ** 2) * 100, 3)\n",
        "t2 = round((1 - math.tanh(math.tanh(math.tanh(math.tanh(100)))) ** 2) * (1 - math.tanh(math.tanh(math.tanh(100))) ** 2) \n",
        "           * (1 - math.tanh(math.tanh(100)) ** 2) * math.tanh(100), 3)\n",
        "t3 = round((1 - math.tanh(math.tanh(math.tanh(math.tanh(100)))) ** 2) * (1 - math.tanh(math.tanh(math.tanh(100))) ** 2)\n",
        "      * math.tanh(math.tanh(100)), 3)\n",
        "t4 = round((1 - math.tanh(math.tanh(math.tanh(math.tanh(100)))) ** 2) * math.tanh(math.tanh(math.tanh(100))), 3)\n",
        "# ReLU activation \n",
        "r1 = round(dReLU(ReLU(ReLU(ReLU(100)))) * dReLU(ReLU(ReLU(100))) * dReLU(ReLU(100)) * dReLU(100) * 100, 3)\n",
        "r2 = round(dReLU(ReLU(ReLU(ReLU(100)))) * dReLU(ReLU(ReLU(100))) * dReLU(ReLU(100)) * ReLU(100), 3)\n",
        "r3 = round(dReLU(ReLU(ReLU(ReLU(100)))) * dReLU(ReLU(ReLU(100))) * ReLU(ReLU(100)), 3)\n",
        "r4 = round(dReLU(ReLU(ReLU(ReLU(100)))) * ReLU(ReLU(ReLU(100))), 3)\n",
        "answer1, answer2 = [t1, t2, t3, t4], [r1, r2, r3, r4]\n",
        "\n",
        "print(answer1, answer2, sep=',')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC0ghEU8DANV",
        "outputId": "c73c5d06-0e10-415e-f455-40579284894b"
      },
      "id": "eC0ghEU8DANV",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 0.168, 0.304, 0.436],[100, 100, 100, 100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CmEDZWHyDAKs"
      },
      "id": "CmEDZWHyDAKs",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}